# AI 功能优化方案

## 一、现状分析

### 1.1 现有AI功能
项目当前集成了以下AI功能：
1. **AI错题分析** - 分析学生错题原因并给出解题思路
2. **AI主观题批改** - 智能批改主观题并给出得分和评语
3. **AI智能出题** - 根据文本内容生成题目
4. **AI知识点提取** - 从文本中提取核心知识点

### 1.2 支持的AI提供商
- DeepSeek (默认)
- 通义千问 (Qwen)

### 1.3 当前实现的优点
- 支持多AI提供商切换
- 使用Java原生HttpClient，无额外依赖
- 有基本的JSON清洗逻辑
- 使用Header传递API Key，安全性较好

## 二、存在的问题

### 2.1 代码质量问题
1. **代码重复严重** - 每个AI方法都有重复的HTTP请求逻辑
2. **缺少统一的错误处理** - 异常处理分散在各个方法中
3. **JSON解析逻辑不够健壮** - extractJson方法对某些边界情况处理不完善
4. **缺少日志记录** - 难以追踪AI调用情况和排查问题

### 2.2 性能问题
1. **无缓存机制** - 相同的请求会重复调用AI接口，浪费资源
2. **无请求重试** - 网络波动时容易失败
3. **超时时间过长** - 3-4分钟的超时影响用户体验
4. **无并发控制** - 可能导致短时间内大量AI请求

### 2.3 配置和扩展性问题
1. **AI Provider配置硬编码** - 难以添加新的AI提供商
2. **缺少配置中心** - API Key、超时时间等配置散落在代码中
3. **缺少降级策略** - AI服务不可用时没有备选方案

### 2.4 监控和运维问题
1. **无调用统计** - 无法了解AI功能使用情况
2. **无成本监控** - 无法追踪AI调用成本
3. **无性能监控** - 无法了解响应时间分布
4. **无限流机制** - 容易被滥用导致成本失控

## 三、优化方案

### 3.1 代码重构
#### 3.1.1 提取通用HTTP客户端
```java
// 新增 AiHttpClient 工具类
- 统一管理HTTP请求
- 统一处理重试逻辑
- 统一处理超时配置
- 统一处理错误码
```

#### 3.1.2 优化JSON解析
```java
// 增强 extractJson 方法
- 支持更多JSON格式
- 增加容错能力
- 添加详细的日志
```

#### 3.1.3 抽象AI Provider
```java
// 新增 AiProvider 接口和实现类
- DeepSeekProvider
- QwenProvider
- 支持策略模式，易于扩展
```

### 3.2 性能优化
#### 3.2.1 添加缓存机制
```java
// 使用 Redis 缓存AI响应
- 对于相同的问题分析，直接返回缓存结果
- 设置合理的过期时间（如1小时）
- 支持手动清除缓存
```

#### 3.2.2 实现请求重试
```java
// 添加重试机制
- 最多重试3次
- 指数退避策略
- 仅对可重试的错误进行重试
```

#### 3.2.3 优化超时配置
```java
// 分级超时设置
- 连接超时：10秒
- 读取超时：
  - 错题分析：30秒
  - 智能出题：60秒
  - 主观题批改：30秒
  - 知识点提取：30秒
```

#### 3.2.4 并发控制
```java
// 使用 Semaphore 限制并发
- 全局最大并发：10个请求
- 单用户最大并发：2个请求
```

### 3.3 配置管理
#### 3.3.1 外部化配置
```yaml
# application.yml
ai:
  providers:
    deepseek:
      url: https://api.deepseek.com/chat/completions
      model: deepseek-chat
      timeout: 60000
    qwen:
      url: https://dashscope.aliyuncs.com/compatible-mode/v1/chat/completions
      model: qwen-plus
      timeout: 60000
  cache:
    enabled: true
    ttl: 3600
  retry:
    maxAttempts: 3
    backoff: 1000
  rateLimit:
    enabled: true
    maxConcurrent: 10
    maxPerUser: 2
```

#### 3.3.2 动态提供商注册
```java
// 支持通过配置文件添加新的AI提供商
// 无需修改代码
```

### 3.4 监控和统计
#### 3.4.1 调用统计
```java
// 新增 AiCallLog 实体
- 记录每次AI调用
- 统计成功/失败次数
- 统计响应时间
- 统计Token消耗
```

#### 3.4.2 成本监控
```java
// 新增成本统计接口
- 按用户统计
- 按功能统计
- 按时间段统计
```

#### 3.4.3 性能监控
```java
// 集成 Prometheus 指标
- ai_request_total
- ai_request_duration
- ai_request_errors
- ai_cache_hits
```

#### 3.4.4 限流保护
```java
// 使用 Redis + Lua 实现限流
- 按用户限流：每分钟10次
- 全局限流：每分钟100次
- 返回友好的限流提示
```

### 3.5 用户体验优化
#### 3.5.1 流式响应
```java
// 支持 SSE (Server-Sent Events)
- AI分析实时返回
- 提升用户感知速度
```

#### 3.5.2 降级策略
```java
// AI服务不可用时
- 返回预设的通用建议
- 提示用户稍后重试
- 自动切换备用提供商
```

#### 3.5.3 提示词优化
```java
// 优化各功能的提示词
- 更精确的指令
- 更严格的输出格式要求
- 减少AI返回错误格式的概率
```

## 四、实施计划

### Phase 1: 基础重构（1-2天）
- [x] 提取 AiHttpClient 工具类
- [x] 优化 JSON 解析逻辑
- [x] 添加详细日志
- [x] 统一异常处理

### Phase 2: 性能优化（1-2天）
- [ ] 集成 Redis 缓存
- [ ] 实现请求重试机制
- [ ] 优化超时配置
- [ ] 添加并发控制

### Phase 3: 配置和扩展性（1天）
- [ ] 外部化配置
- [ ] 实现提供商接口
- [ ] 支持动态注册提供商

### Phase 4: 监控和运维（1-2天）
- [ ] 添加调用统计
- [ ] 实现成本监控
- [ ] 集成 Prometheus 指标
- [ ] 实现限流保护

### Phase 5: 体验优化（1天）
- [ ] 支持流式响应
- [ ] 实现降级策略
- [ ] 优化提示词

## 五、预期效果

### 5.1 代码质量
- 代码重复率降低 70%
- 可维护性提升
- 易于添加新的AI提供商

### 5.2 性能提升
- 缓存命中率 > 30%，相同请求响应时间缩短 90%
- 重试机制提升成功率 5-10%
- 并发控制防止系统过载

### 5.3 用户体验
- 平均响应时间缩短 50%（得益于缓存）
- 失败率降低 50%（得益于重试）
- 更友好的错误提示

### 5.4 运维效率
- 可视化监控面板
- 实时成本追踪
- 自动告警机制
- 详细的调用日志

## 六、风险评估

### 6.1 技术风险
- **Redis依赖** - 需要确保Redis服务稳定
- **缓存一致性** - 需要合理设置缓存过期时间
- **性能监控** - Prometheus集成需要额外资源

### 6.2 业务风险
- **缓存命中率** - 如果题目变化频繁，缓存效果有限
- **限流影响** - 限流可能影响高峰时段的使用

### 6.3 缓解措施
- 缓存降级：Redis不可用时直接调用AI
- 配置可调：限流阈值可通过配置调整
- 监控告警：及时发现和处理异常

## 七、后续规划

### 7.1 功能扩展
- 支持更多AI提供商（OpenAI、Claude等）
- AI对话功能（学习助手）
- AI生成试卷
- AI学情分析报告

### 7.2 智能优化
- 根据历史数据优化提示词
- 自动选择最优AI提供商
- 智能调整缓存策略

### 7.3 成本优化
- 根据题目难度选择合适的模型
- 批量处理降低调用次数
- 本地模型部署探索
